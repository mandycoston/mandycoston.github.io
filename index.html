<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }

  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }

  a.button, a.button:focus {
    font-size: 15px;
    font-weight: bold;
    border: 2px solid black;
    border-radius: 20px;
    margin: 5px;
    padding: 6px
  }
  a.button:hover {
  color: white;
  background-color: #1772d0;
  }
  
  body,td,th {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  div.heading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600; /* 1000 */
  }
  div.authors {
    margin-top: 3px;
    margin-bottom: 8px
  }

  strong {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 29px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 50px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }

  img.pub {
    padding: 0px;
    margin: 0px;
  }

  .paper {
    font-size: 12px;
    margin-left: 30px;
  }

  pre {
    border: solid;
    border-width: 1px;
    padding: 5px;
  }

  sticker {
    color:white;
    background-color: red;
    font-size: 13px;
    font-weight: bold;
    vertical-align: center;
    padding-left: 2px;
    padding-right: 2px;
  }

  </style>
  <link rel="shortcut icon" href="https://www.cs.cmu.edu/sites/default/files/favicon_0.ico" type="image/vnd.microsoft.icon">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Amanda Coston</title>
  <meta name="Amanda Coston's Homepage" http-equiv="Content-Type" content="Amanda Coston's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Nunito:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Amanda Coston</font><br> -->
    <pageheading>Amanda Coston</pageheading><br>
    <b>email</b>:&nbsp
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <script>
    emailScramble = new scrambledString(document.getElementById('email'),
        'emailScramble', 'doc@cuoctes.mu.san',
        [17,3,9,8,12,14,6,2,5,16,4,11,13,18,15,10,1,7]);
    </script>
  </p>

  <tr>
    <td width="40%" valign="top"><a href="media/mandy.jpeg"><img src="media/mandy.jpeg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    <a href="cv.pdf">CV</a> |
    <!-- <a href="bio.text" target="_blank">Bio</a> | -->
    <a href="https://scholar.google.com/citations?user=8U7d-_MAAAAJ&hl=en">Google Scholar</a> |
    <a href="https://github.com/mandycoston">Github</a> |
    <a href="https://twitter.com/amandacoston">Twitter</a>
    </p>
    </td>
    <td width="60%" valign="top" align="justify">
      <p>
        Amanda Coston is a PhD student in <a href="https://www.ml.cmu.edu/current-students/joint-phd-in-machine-learning-and-public-policy-requirements.html">Machine Learning and Public Policy</a> at <a href="https://www.cmu.edu">Carnegie Mellon University</a> (CMU). She is interested in how machine learning can improve decision-making in societally high-stakes settings. She is particularly interested in how to make decision-making systems more reliable and more equitable.   
      </p>
      <p><b>She is on the academic job market for 2022-2023.</b> </p>
      <p>
        Her research addresses real-world data problems that challenge the reliability of algorithmic decision support systems and data-driven policy-making. A central focus of her research is identifying when algorithms, data used for policy-making, and human decisions disproportionately impact marginalized groups. Much of her work uses doubly-robust techniques for bias correction. She is advised by <a href= "https://www.andrew.cmu.edu/user/achoulde/">Alexandra Chouldechova</a> and <a href="http://www.ehkennedy.com/">Edward H. Kennedy.</a>
      </p>
      <p>
        Amanda is a Rising Star in <a href="https://risingstars.utexas.edu/">EECS</a>, <a href="https://ml.umd.edu/rising-stars">Machine Learning</a> and <a href="https://datascience.uchicago.edu/rising-stars/">Data Science</a>, <a href="https://research.facebook.com/fellows/coston-amanda-lee/"> Meta Research PhD Fellow</a>, <a href="https://www.nsfgrfp.org/resources/about-grfp/">NSF GRFP Fellow</a> and <a href="https://www.cmu.edu/news/stories/archives/2020/august/gates-presidential-fellows.html">K & L Gates Presidential Fellow</a> in Ethics and Computational Technologies. In 2019 she was a recipient of the Tata Consultancy Services (TCS) Presidential Fellowship. Her research on counterfactual risk assessments and evaluation for child welfare screening won the 2018 <a href="https://www.cmu.edu/cmnews/extra/060113_konda.html">Suresh Konda Best First Student Research Paper Award</a> from the <a href="https://www.heinz.cmu.edu/">Heinz College</a>.
      </p>

    </td>
  </tr>
</table><hr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;News</sectionheading></td></tr>
</table>

<div style="height:250px;overflow:auto;">
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Nov 15, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Our paper on <a href = "https://arxiv.org/abs/2206.14983">evaluating justifiability of ML in high-stakes decisions</a> was accepted to <a href="https://satml.org/">SATML</a>. Looking forward to presenting in Raleigh in February!
    </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Nov 10, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Presented at the Symposium on Frontiers of Machine Learning & AI at <a href="https://viterbischool.usc.edu/">USC Viterbi</a>.
    </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Nov 01, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Presented at the ML seminar series at University of Maryland as a <a href="https://ml.umd.edu/rising-stars">Rising Star in Machine Learning</a>.
    </td>
  </tr>
  
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 18, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Presented work on algorithmic fairness in the Rashomon set at  <a href="https://meetings.informs.org/wordpress/indianapolis2022/"> INFORMS</a> session on Finding Sets of Near-Optimal Solutions for MIPs. 
          </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 13, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">
      &#127942; Accepted to <a href="https://datascience.uchicago.edu/rising-stars/">Rising Stars in Data Science</a> at the University of Chicago in Nov 2022!
    </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 10, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">
      &#127942; Accepted to <a href="https://ml.umd.edu/rising-stars">Rising Stars in Machine Learning</a> at the University of Maryland in Nov 2022!
    </td>
  </tr>
 
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 06, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Presented a poster on validity in decision making algorithms at <a href="https://eaamo.org/#home"> EAAMO</a> and attending the doctoral consortium!  
          </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 02, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Invited talk on counterfactual audit for racial bias at <a href="http://www.ams.org/meetings/sectional/2301_progfull.html"> American Mathematical Society Sectional Meeting on Causality</a>. 
          </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Sep 23, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Presented work on counterfactual risk assessments under unmeasured confounding at  <a href="https://economics.brown.edu/orlando-bravo-center-economic-research"> Brown's Bravo Center Workshop on the Economics of Algorithms</a>. 
    </td>
  </tr> 
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Sep 12, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Check out our <a href="counterfactual-under-unmeasured-conf-RCK.pdf"> draft</a> of counterfactual risk assessments under unmeasured confounding with Ashesh Rambachan and Ed Kennedy.
  </td>
  </tr> 
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Aug 16, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Attended the  <a href="https://cra.org/ccc/events/artificial-intelligence-operations-research-workshop-ii/"> CCC and INFORMS Artificial Intelligence/Operations Research Workshop </a>in Atlanta, GA.
          </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Aug 01, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">
      &#127942; Accepted to <a href="https://risingstars.utexas.edu/">Rising Stars in EECS</a> at UT-Austin in Oct 2022!
    </td>
  </tr>

<tr>
    <td width="15%" valign="top" align="right"><b><i>Jul 19, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">  <a href="https://arxiv.org/abs/2206.14983"> Validity in ML paper</a> accepted to <a href="https://eaamo.org/#home">Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO)</a> 
      (joint work with <a href="https://annakawakami.com/">Anna</a>, <a href="https://haiyizhu.com/">Haiyi</a>, <a href="https://www.thecoalalab.com/kenholstein">Ken</a>, and <a href="https://www.cs.cmu.edu/~hheidari/">Hoda</a>). 
         </td> 
  </tr>
  
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Jul 19, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Released preprint of our manuscript on <a href="https://arxiv.org/abs/2207.09016"> role of the geometric mean in case-control studies</a> (joint work with <a href="http://www.ehkennedy.com/">Edward Kennedy</a>). 
          </td>
  </tr>

  <tr>
    <td width="15%" valign="top" align="right"><b><i>Jul 15, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Presented work on auditing administrative data for bias at <a href="https://reglab.stanford.edu/"> Stanford RegLab</a>. 
          </td>
  </tr>
  
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Jun 30, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Released a pre-print of <a href="https://arxiv.org/abs/2206.14983"> our paper</a>  on using validity as a lens to evaluate justified use of data-driven decision making  
       (joint work with <a href="https://annakawakami.com/">Anna</a>, <a href="https://haiyizhu.com/">Haiyi</a>, <a href="https://www.thecoalalab.com/kenholstein">Ken</a>, and <a href="https://www.cs.cmu.edu/~hheidari/">Hoda</a>). 
          </td>
  </tr>
  
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Jun 24, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Chaired the session on <a href ="https://facctconference.org/2022/schedule.html">responsible data management</a> at ACM FAccT 2022. 
          </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>May 24, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> <sticker>TALK</sticker> Oral presentation at <a href="https://ctml.berkeley.edu/acic-2022-room-1"> ACIC</a> on counterfactual audits for racial bias in police traffic stops (joint work with <a href="http://www.ehkennedy.com/">Edward Kennedy</a>). 
          </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>May 24, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Poster session at ACIC on counterfactual risk assessments under unmeasured confounding (joint work with <a href= "https://asheshrambachan.github.io/">Ashesh Rambachan</a> and <a href="http://www.ehkennedy.com/">Edward Kennedy</a>). 
          </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Mar 15, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">
      &#127942; Accepted to <a href="https://facctconference.org/2022/cfdc.html">FAccT doctoral consortium</a> in Seoul, South Korea!
    </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Feb 12, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">
      &#127942; Accepted to University of Michigan <a href="https://midas.umich.edu/future-leaders-summit-2022/">Michigan Future Leaders Summit</a> hosted by <a href="https://midas.umich.edu/">Michigan Institute for Data Science (MIDAS)</a>!
    </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Feb 4, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> Proposed thesis, <a href="https://www.cs.cmu.edu/calendar/157530883">Principled Machine Learning for High-stakes Decisions</a>. <br> Committee: <a href="http://www.ehkennedy.com/">Ed Kennedy</a>, <a href= "https://www.andrew.cmu.edu/user/achoulde/">Alex Chouldechova</a>, <a href="https://www.cs.cmu.edu/~hheidari/">Hoda Heidari</a>, & <a href="https://sendhil.org/">Sendhil Mullainathan</a> 
    </td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Feb 2, 2022</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"> &#127942; Awarded the <a href="https://research.facebook.com/fellows/coston-amanda-lee/"> Meta Research PhD Fellowship</a>! Thanks Meta Research for the support!</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Oct 21, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"><sticker>TALK</sticker> Invited talk at <a href="https://www.merck.com/">Merck</a> Data Science All Hands</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Sep, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">Joined the <a href="https://www.cmu.edu/stugov/gsa/About-the-GSA/Committees.html">Graduate Student Assembly Campus Affairs Committee</a> where I will focus on sustainability efforts at CMU.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Jun 07, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">Started internship at <a href="https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/">Facebook Responsible AI</a>.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>May 18, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">Featured on <a href="https://www.placekey.io/blog/amanda-coston-carnegie-mellon">Placekey Spotlight</a>.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>May 08, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">Our <a href="http://proceedings.mlr.press/v139/coston21a.html">research paper</a> on characterizing fairness over the set of good models under selective labels accepted at <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>May 04, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"><sticker>TALK</sticker> Invited talk at <a href="https://jhsphcausalinference.weebly.com/">Johns Hopkins Causal Inference Working Group</a> on counterfactual predictions for decision-making. Check out the <a href="https://www.youtube.com/watch?v=Ubt_sH2qRMg">video here</a>!</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Apr 22, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"><sticker>TALK</sticker> Invited talk at <a href="https://www.placekey.io/">PlaceKey</a> COVID-19 Research Consortium on auditing mobility data for disparate coverage by race and age. Check out the <a href="https://www.placekey.io/seminars/mobility-data-used-to-respond-to-covid19-could-be-biased">video here</a>!</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Apr 16, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;">CMU <a href ="https://blog.ml.cmu.edu/2021/04/16/counterfactual-predictions-under-runtime-confounding/"> ML Blog Post </a> on counterfactual predictions under runtime confounding.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Apr 05, 2021</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"><i>The Wall Street Journal</i> featured our research on auditing mobility data for demographic bias! The piece is titled <a href ="https://www.wsj.com/articles/smartphone-location-data-can-leave-out-those-most-hit-by-covid-19-11617627615"><i>Smartphone Location Data Can Leave Out Those Most Hit by Covid-19</i></a>.</td>
  </tr>
  <tr>
    <td width="15%" valign="top" align="right"><b><i>Nov 18, 2020</i></b></td>
    <td width="85%" valign="top" align="left" style="padding-left: 10px;"><i>VentureBeat</i> featured our research on auditing mobility data for demographic bias! The piece is titled <a href ="https://venturebeat.com/2020/11/18/stanford-and-carnegie-mellon-find-race-and-age-bias-in-mobility-data-that-drives-covid-19-policy/"> <i>Stanford and Carnegie Mellon find race and age bias in mobility data that drives COVID-19 policy</i></a>.</td>
  </tr>
</table>
</div>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Research talk</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <center>
  <video width=95% autoplay playsinline controls>
    <source src="media/midas.mp4">
  </video>
</center>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Working papers</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://www.youtube.com/watch?v=UuDdxtQEc7I&list=PLHtzc5hGcx9sjwuETR3izb27TJSauQ4EO" target="_blank"><img class="pub" src="website-photos/madison-police.png" alt="image not found" width="85%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://www.youtube.com/watch?v=UuDdxtQEc7I&list=PLHtzc5hGcx9sjwuETR3izb27TJSauQ4EO" target="_blank">
      <div class="heading">Counterfactual audit of racial bias in police traffic stops</div></a>
      <div class="authors"><b>A. Coston</b>, E. H. Kennedy</div>
      <i>American Causal Inference Conference (ACIC) </i>, 2022</i>
      <div style="color: red;"><i>Oral presentation (20% selection rate)</i></div>
      </p>

      <div>
      <a href="javascript:toggleblock('police_stops_abs')">Abstract</a> |
      <a href="https://www.youtube.com/watch?v=UuDdxtQEc7I&list=PLHtzc5hGcx9sjwuETR3izb27TJSauQ4EO" target="_blank">Talk</a>


      <p align="justify"> <i id="police_stops_abs">Racial bias in criminal justice has profound consequences. This bias harms not only the participant of the encounter but also has far-reaching implications, particularly in the era of big data. These interactions are often recorded and used to build algorithms that shape future encounters with the criminal justice system. In order to guard against automating biases in these high-stakes algorithms, we must identify when and where bias occurs in the criminal justice pipeline. 

        We consider racial bias in one of the most common points of entry: police traffic stops. Building on the tradition that uses the "veil of darkness" to test for racial bias in officer's decisions to stop, we propose a counterfactual audit for racial bias that clarifies the assumptions needed to identify racial bias. A central challenge is that standard measures of effect are not identifiable due to the outcome-dependent sampling of police traffic stop data. As a solution, we identify an odds ratio that recovers a test for differences in the race-conditional risk ratios under Bernoulli sampling. We propose an efficient estimator for the identified odds ratio using doubly-robust techniques that allow for flexible, non-parametric estimation. We present empirical results on the Stanford Open Policing data.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('police_stops_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2207.09016" target="_blank"><img class="pub" src="website-photos/geomean.png" alt="image not found" width="80%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/abs/2207.09016" target="_blank">
      <div class="heading">The role of the geometric mean in case-control studies</div></a>
      <div class="authors"><b>A. Coston</b>, E. H. Kennedy</div>
      </p>

      <div>
      <a href="javascript:toggleblock('geometric_mean_abs')">Abstract</a> |
      <a href="https://arxiv.org/abs/2207.09016" target="_blank">ArXiv</a>

      <p align="justify"> <i id="geometric_mean_abs">Historically used in settings where the outcome is rare or data collection is expensive, outcome-dependent sampling is relevant to many modern settings where data is readily available for a biased sample of the target population, such as public administrative data. Under outcome-dependent sampling, common effect measures such as the average risk difference and the average risk ratio are not identified, but the conditional odds ratio is. Aggregation of the conditional odds ratio is challenging since summary measures are generally not identified. Furthermore, the marginal odds ratio can be larger (or smaller) than all conditional odds ratios. This so-called non-collapsibility of the odds ratio is avoidable if we use an alternative aggregation to the standard arithmetic mean. We provide a new definition of collapsibility that makes this choice of aggregation method explicit, and we demonstrate that the odds ratio is collapsible under geometric aggregation. We describe how to partially identify, estimate, and do inference on the geometric odds ratio under outcome-dependent sampling. Our proposed estimator is based on the efficient influence function and therefore has doubly robust-style properties.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('geometric_mean_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr><td><div></div></td></tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://www.cs.cmu.edu/~acoston/counterfactual-under-unmeasured-conf-RCK.pdf" target="_blank"><img class="pub" src="website-photos/unmeasured-confounding.png" alt="image not found" width="80%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://www.cs.cmu.edu/~acoston/counterfactual-under-unmeasured-conf-RCK.pdf" target="_blank">
      <div class="heading"> Counterfactual risk assessments under unmeasured confounding</div></a>
      <div class="authors">A. Rambachan, <b>A. Coston</b>, E. H. Kennedy</div>
      <i>NeurIPS Workshop on Algorithmic Fairness through the Lens of Causality and Privacy</i>, 2022
      </p>

      <div>
      <a href="javascript:toggleblock('cfactual_risk_asses_abs')">Abstract</a> |
      <a href="https://www.cs.cmu.edu/~acoston/counterfactual-under-unmeasured-conf-RCK.pdf" target="_blank">Paper</a> 

      <p align="justify"> <i id="cfactual_risk_asses_abs">Statistical risk assessments inform consequential decisions such as pretrial release in criminal justice, and loan approvals in consumer finance. Such risk assessments make counterfactual predictions, predicting the likelihood of an outcome under a proposed decision (e.g., what would happen if we approved this loan?). A central challenge, however, is that there may have been unobserved confounders that jointly affected past decisions and outcomes in the historical data. This paper proposes a tractable mean outcome sensitivity model that bounds the extent to which unmeasured confounders could affect outcomes on average. The mean outcome sensitivity model partially identifies the conditional likelihood of the outcome under the proposed decision as well as popular predictive performance metrics (accuracy, calibration, TPR, FPR, etc.) and commonly-used predictive disparities, and we derive their sharp identified sets. We then solve three tasks that are essential to deploying statistical risk assessments in high-stakes settings. First, we propose a learning procedure based on doubly-robust pseudo-outcomes that estimates bounds on the conditional likelihood of the outcome under the proposed decision, and derive a bound on its integrated mean square error. Second, we show how our estimated bounds on the conditional likelihood of the outcome under the proposed decision can be translated into a robust, plug-in decision-making policy, and derive bounds on its worst-case regret relative to the max-min optimal decision rule. Third, we develop estimators of the bounds on the predictive performance metrics of existing risk assessment that are based on efficient influence functions and cross-fitting, and only require black-box access to the risk assessment.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('cfactual_risk_asses_abs');
      </script>
      </div>
    </td>
  </tr>

</table>
<br>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://openreview.net/forum?id=LghfT9-phCc" target="_blank"><img class="pub" src="website-photos/justi.png" alt="image not found" width="80%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://openreview.net/forum?id=LghfT9-phCc" target="_blank">
      <div class="heading">A Validity Perspective on Evaluating the Justified Use of Data-driven Decision-making Algorithms</div></a>
      <div class="authors"><b>A. Coston</b>, A. Kawakami, H. Zhu, K. Holstein, H. Heidari</div>
      <i>IEEE Conference on Secure and Trustworthy Machine Learning (SATML), to appear
        </i>, 2023
      </p>

      <div>
      <a href="javascript:toggleblock('satml23_abs')">Abstract</a> |
      <a href="https://openreview.net/forum?id=LghfT9-phCc" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/2011.07194" target="_blank">ArXiv</a> 


<p align="justify"> <i id="satml23_abs">Recent research increasingly brings to question the appropriateness of using predictive tools in complex, real-world tasks. While a growing body of work has explored ways to improve value alignment in these tools, comparatively less work has centered concerns around the fundamental justifiability of using these tools. This work seeks to center validity considerations in deliberations around whether and how to build data-driven algorithms in high-stakes domains. Toward this end, we translate key concepts from validity theory to predictive algorithms. We apply the lens of validity to re-examine common challenges in problem formulation and data issues that jeopardize the justifiability of using predictive algorithms and connect these challenges to the social science discourse around validity. Our interdisciplinary exposition clarifies how these concepts apply to algorithmic decision making contexts. 
  We demonstrate how these validity considerations could distill into a series of high-level questions intended to promote and document reflections on the legitimacy of the predictive task and the suitability of the data.</i></p>
<script xml:space="preserve" language="JavaScript">
  hideblock('satml23_abs');
</script>
</div>
</td>
</tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2011.07194" target="_blank"><img class="pub" src="website-photos/leveraging.png" alt="image not found" width="80%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/abs/2011.07194" target="_blank">
      <div class="heading">Leveraging Administrative Data for Bias Audits: Assessing Disparate Coverage with Mobility Data for COVID-19 Policy</div></a>
      <div class="authors"><b>A. Coston</b>, N. Guha, L. Lu, D. Ouyang, A. Chouldechova, D. Ho</div>
      <i>ACM Conference on Fairness, Accountability, and Transparency (FAccT)</i>, 2021
      </p>

      <div>
      <a href="javascript:toggleblock('facct21_abs')">Abstract</a> |
      <a href="https://dl.acm.org/doi/10.1145/3442188.3445881" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/2011.07194" target="_blank">ArXiv</a> |
      <a href="https://www.youtube.com/watch?v=K2axD2sv-Uc" target="_blank">Talk</a>


      <p align="justify"> <i id="facct21_abs">Anonymized smartphone-based mobility data has been widely adopted in devising and evaluating COVID-19 response strategies such as the targeting of public health resources. Yet little attention has been paid to measurement validity and demographic bias, due in part to the lack of documentation about which users are represented as well as the challenge of obtaining ground truth data on unique visits and demographics. We illustrate how linking large-scale administrative data can enable auditing mobility data for bias in the absence of demographic information and ground truth labels. More precisely, we show that linking voter roll data containing individual-level voter turnout for specific voting locations along with race and age can facilitate the construction of rigorous bias and reliability tests. Using data from North Carolina's 2018 general election, these tests illuminate a sampling bias that is particularly noteworthy in the pandemic context: older and non-white voters are less likely to be captured by mobility data. We show that allocating public health resources based on such mobility data could disproportionately harm high-risk elderly and minority groups.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('facct21_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2101.00352" target="_blank"><img class="pub" src="website-photos/characterizing-fairness.png" alt="image not found" width="75%" style="border-width: 1px; border-style: solid; border-color: black;"></a></td>
    <td width="55%" valign="top">
      <p><a href="https://arxiv.org/abs/2101.00352" target="_blank">
      <div class="heading">Characterizing Fairness over the Set of Good Models Under Selective Labels</div></a>
      <div class="authors"><b>A. Coston</b>, A. Rambachan, A. Chouldechova</div>
      <i>International Conference on Machine Learning (ICML)</i>, 2021
      </p>

      <div>
      <a href="javascript:toggleblock('icml21_abs')">Abstract</a> |
      <a href="http://proceedings.mlr.press/v139/coston21a.html" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/2101.00352" target="_blank">ArXiv</a> |
      <a href="https://icml.cc/virtual/2021/poster/8471" target="_blank">Talk</a>


      <p align="justify"> <i id="icml21_abs">Algorithmic risk assessments are used to inform decisions in a wide variety of high-stakes settings. Often multiple predictive models deliver similar overall performance but differ markedly in their predictions for individual cases, an empirical phenomenon known as the "Rashomon Effect." These models may have different properties over various groups, and therefore have different predictive fairness properties. We develop a framework for characterizing predictive fairness properties over the set of models that deliver similar overall performance, or "the set of good models." Our framework addresses the empirically relevant challenge of selectively labelled data in the setting where the selection decision and outcome are unconfounded given the observed data features. Our framework can be used to 1) replace an existing model with one that has better fairness properties; or 2) audit for predictive bias. We illustrate these uses cases on a real-world credit-scoring task and a recidivism prediction task.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('icml21_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr><td><div></div></td></tr>
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2006.16916" target="_blank"><img class="pub" src="website-photos/runtime-confounding.png" alt="image not found" width="85%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/abs/2006.16916" target="_blank">
      <div class="heading">Counterfactual Predictions under Runtime Confounding</div></a>
      <div class="authors"><b>A. Coston</b>, E. H. Kennedy, A. Chouldechova</div>
      <i>Neural Information Processing Systems (NeurIPS)</i>, 2020
      </p>

      <div>
      <a href="javascript:toggleblock('neurips20_abs')">Abstract</a> |
      <a href="https://proceedings.neurips.cc/paper/2020/file/2b64c2f19d868305aa8bbc2d72902cc5-Paper.pdf" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/2006.16916" target="_blank">ArXiv</a> |
      <a href="https://blog.ml.cmu.edu/2021/04/16/counterfactual-predictions-under-runtime-confounding/" target="_blank">Blog</a><br><br>


      <p align="justify"> <i id="neurips20_abs">Algorithms are commonly used to predict outcomes under a particular decision or intervention, such as predicting whether an offender will succeed on parole if placed under minimal supervision. Generally, to learn such counterfactual prediction models from observational data on historical decisions and corresponding outcomes, one must measure all factors that jointly affect the outcomes and the decision taken. Motivated by decision support applications, we study the counterfactual prediction task in the setting where all relevant factors are captured in the historical data, but it is either undesirable or impermissible to use some such factors in the prediction model. We refer to this setting as runtime confounding. We propose a doubly-robust procedure for learning counterfactual prediction models in this setting. Our theoretical analysis and experimental results suggest that our method often outperforms competing approaches. We also present a validation procedure for evaluating the performance of counterfactual prediction methods.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('neurips20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="left"><a href="https://arxiv.org/abs/1909.00066" target="_blank"><img class="pub" src="website-photos/counterfactual-evaluation.png" alt="image not found" width="90%"></a></td>
    <td width="55%" valign="top">
      <p><a href="https://arxiv.org/abs/1909.00066" target="_blank">
      <div class="heading">Counterfactual Risk Assessments, Evaluation, and Fairness</div></a>
      <div class="authors"><b>A. Coston</b>, A. Mishler, E. H. Kennedy, A. Chouldechova</div>
      <i>ACM Conference on Fairness, Accountability, and Transparency (FAccT)</i>, 2020
      </p>

      <div>
      <a href="javascript:toggleblock('facct20_abs')">Abstract</a> |
      <a href="https://dl.acm.org/doi/abs/10.1145/3351095.3372851" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/1909.00066" target="_blank">ArXiv</a> |
      <a href="https://www.youtube.com/watch?v=9zfi3heBYUs" target="_blank">Talk</a>


      <p align="justify"> <i id="facct20_abs">Algorithmic risk assessments are increasingly used to help humans make decisions in high-stakes settings, such as medicine, criminal justice and education. In each of these cases, the purpose of the risk assessment tool is to inform actions, such as medical treatments or release conditions, often with the aim of reducing the likelihood of an adverse event such as hospital readmission or recidivism. Problematically, most tools are trained and evaluated on historical data in which the outcomes observed depend on the historical decision-making policy. These tools thus reflect risk under the historical policy, rather than under the different decision options that the tool is intended to inform. Even when tools are constructed to predict risk under a specific decision, they are often improperly evaluated as predictors of the target outcome. Focusing on the evaluation task, in this paper we define counterfactual analogues of common predictive performance and algorithmic fairness metrics that we argue are better suited for the decision-making context. We introduce a new method for estimating the proposed metrics using doubly robust estimation. We provide theoretical results that show that only under strong conditions can fairness according to the standard metric and the counterfactual metric simultaneously hold. Consequently, fairness-promoting methods that target parity in a standard fairness metric may --- and as we show empirically, do --- induce greater imbalance in the counterfactual analogue. We provide empirical comparisons on both synthetic data and a real world child welfare dataset to demonstrate how the proposed method improves upon standard practice.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('facct20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="left"><a href="https://arxiv.org/abs/1910.07162" target="_blank"><img class="pub" src="website-photos/conditional-learning-fair-representations.png" alt="image not found" width="90%"></a></td>
    <td width="65%" valign="top">
      <p><a href="https://arxiv.org/abs/1910.07162" target="_blank">
      <div class="heading">Conditional Learning of Fair Representations</div></a>
      <div class="authors">H. Zhao, <b>A. Coston</b>, T. Adel, G. J. Gordon</div>
      <i>International Conference on Learning Representations <br>(ICLR)</i>, 2020
      </p>

      <div>
      <a href="javascript:toggleblock('iclr20_abs')">Abstract</a> |
      <a href="https://openreview.net/forum?id=Hkekl0NFPr" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/1910.07162" target="_blank">ArXiv</a> |
      <a href="https://iclr.cc/virtual_2020/poster_Hkekl0NFPr.html" target="_blank">Talk</a>


      <p align="justify"> <i id="iclr20_abs">We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups in the classification setting. Two key components underpinning the design of our algorithm are balanced error rate and conditional alignment of representations. We show how these two components contribute to ensuring accuracy parity and equalized false-positive and false-negative rates across groups without impacting demographic parity. Furthermore, we also demonstrate both in theory and on two real-world experiments that the proposed algorithm leads to a better utility-fairness trade-off on balanced datasets compared with existing algorithms on learning fair representations for classification.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('iclr20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2007.07796" target="_blank"><img class="pub" src="website-photos/neural-topic-models-survival-small.png" alt="image not found" width="90%"></a></td>
    <td width="65%" valign="top">
      <p><a href="https://arxiv.org/abs/2007.07796" target="_blank">
      <div class="heading">Neural Topic Models with Survival Supervision: Jointly Predicting Time-to-Event Outcomes and Learning How Clinical Features Relate</div></a>
      <div class="authors">L. Li, R. Zuo, <b>A. Coston</b>, J. C. Weiss, G. H. Chen</div>
      <i>International Conference on Artificial Intelligence in Medicine</i>, 2020
      </p>

      <div>
      <a href="javascript:toggleblock('icaim20_abs')">Abstract</a> |
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-59137-3_33" target="_blank">Paper</a> |
      <a href="https://arxiv.org/abs/2007.07796" target="_blank">ArXiv</a>


      <p align="justify"> <i id="icaim20_abs">In time-to-event prediction problems, a standard approach to estimating an interpretable model is to use Cox proportional hazards, where features are selected based on lasso regularization or stepwise regression. However, these Cox-based models do not learn how different features relate. As an alternative, we present an interpretable neural network approach to jointly learn a survival model to predict time-to-event outcomes while simultaneously learning how features relate in terms of a topic model. In particular, we model each subject as a distribution over "topics", which are learned from clinical features as to help predict a time-to-event outcome. From a technical standpoint, we extend existing neural topic modeling approaches to also minimize a survival analysis loss function. We study the effectiveness of this approach on seven healthcare datasets on predicting time until death as well as hospital ICU length of stay, where we find that neural survival-supervised topic models achieves competitive accuracy with existing approaches while yielding interpretable clinical "topics" that explain feature relationships.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('icaim20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr><td><div></div></td></tr>
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://dl.acm.org/doi/10.1145/3306618.3314236" target="_blank"><img class="pub" src="website-photos/transfer-learning.png" alt="image not found" width="85%"></a></td>
    <td width="65%" valign="top">
      <p><a href="https://dl.acm.org/doi/10.1145/3306618.3314236" target="_blank">
      <div class="heading">Fair Transfer Learning with Missing Protected Attributes</div></a>
      <div class="authors"><b>A. Coston</b>, K. N. Ramamurthy, D. Wei, K. R. Varshney, S. Speakman, Z. Mustahsan, S. Chakraborty</div>
      <i>AAAI/ACM Conference on Artificial Intellligence, Ethics, and Society (AIES)</i>, 2019
      </p>

      <div>
      <a href="javascript:toggleblock('aies19_abs')">Abstract</a> |
      <a href="https://dl.acm.org/doi/10.1145/3306618.3314236" target="_blank">Paper</a>


      <p align="justify"> <i id="aies19_abs">Risk assessment is a growing use for machine learning models. When used in high-stakes applications, especially ones regulated by anti-discrimination laws or governed by societal norms for fairness, it is important to ensure that learned models do not propagate and scale any biases that may exist in training data. In this paper, we add on an additional challenge beyond fairness: unsupervised domain adaptation to covariate shift between a source and target distribution. Motivated by the real-world problem of risk assessment in new markets for health insurance in the United States and mobile money-based loans in East Africa, we provide a precise formulation of the machine learning with covariate shift and score parity problem. Our formulation focuses on situations in which protected attributes are not available in either the source or target domain. We propose two new weighting methods: prevalence-constrained covariate shift (PCCS) which does not require protected attributes in the target domain and target-fair covariate shift (TFCS) which does not require protected attributes in the source domain. We empirically demonstrate their efficacy in two applications.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('aies19_abs');
      </script>
      </div>
    </td>
  </tr>


  <!-- <hr style="margin-top: 20px;">
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
    <tr><td><sectionheading>&nbsp;&nbsp;Working Papers</sectionheading></td></tr>
  </table>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  
    <tr>
      <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2011.07194" target="_blank"><img class="pub" src="website-photos/geomean.png" alt="image not found" width="80%"></a></td>
      <td width="60%" valign="top">
        <p><a href="https://arxiv.org/abs/2011.07194" target="_blank">
        <div class="heading">The Role of the Geometric Mean in Case-Control Studies
        </div></a>
        <div class="authors"><b>A. Coston</b>, E. H. Kennedy.</div>
        </p>
  
        <div>
        <a href="javascript:toggleblock('facct21_abs')">Abstract</a> |
        <a href="https://arxiv.org/abs/2207.09016" target="_blank">ArXiv</a> 
  
  
        <p align="justify"> <i id="geomean2022_abs">Historically used in settings where the outcome is rare or data collection is expensive, outcome-dependent sampling is relevant to many modern settings where data is readily available for a biased sample of the target population, such as public administrative data. Under outcome-dependent sampling, common effect measures such as the average risk difference and the average risk ratio are not identified, but the conditional odds ratio is. Aggregation of the conditional odds ratio is challenging since summary measures are generally not identified. Furthermore, the marginal odds ratio can be larger (or smaller) than all conditional odds ratios. This so-called non-collapsibility of the odds ratio is avoidable if we use an alternative aggregation to the standard arithmetic mean. We provide a new definition of collapsibility that makes this choice of aggregation method explicit, and we demonstrate that the odds ratio is collapsible under geometric aggregation. We describe how to partially identify, estimate, and do inference on the geometric odds ratio under outcome-dependent sampling. Our proposed estimator is based on the efficient influence function and therefore has doubly robust-style properties.
        </i></p>
        <script xml:space="preserve" language="JavaScript">
          hideblock('facct21_abs');
        </script>
        </div>
      </td>
    </tr>
   -->


</table><hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Visualization</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr width="90%" valign="center" align="left">
    <td style="padding-left: 4%;">
      <h3 style="margin-bottom: 6px">Opioid Epidemic</h3>
      In 2017, drug overdoses claimed more lives than car accidents. The below maps show opioid hotspots across the United States at various granularities. We used a similarity metric of death rate trajectories derived from Fisher's exact test to perform hierarchical clustering. <br><br>

      <center>
        <a href="start10.html" class="button" target="_blank">County Map</a>
        <a href="100clusters10.html" class="button" target="_blank">100 clusters</a>
        <a href="10clusters10.html" class="button" target="_blank">10 clusters</a>
      </center>
    </td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Awards</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2022</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://datascience.uchicago.edu/rising-stars/">Rising Star in Data Science</a> at the University of Chicago.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2022</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://ml.umd.edu/rising-stars">Rising Star in Machine Learning</a> at the University of Maryland.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2022</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://risingstars.utexas.edu/">Rising Star in EECS 2022</a> at UT-Austin.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2022</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://research.facebook.com/fellows/coston-amanda-lee/"> Meta Research PhD Fellow</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2022</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://midas.umich.edu/future-leaders-summit-2022/">Future Leader in Responsible Data Science</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.cmu.edu/news/stories/archives/2020/august/gates-presidential-fellows.html">K & L Gates Presidential Fellow</a> in Ethics and Computational Technologies.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2019</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Tata Consultancy Services (TCS) Presidential Fellowship.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2018</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.cmu.edu/cmnews/extra/060113_konda.html">Suresh Konda Best First Student Research Paper Award</a> from the <a href="https://www.heinz.cmu.edu/">Heinz College</a> for <a href="https://arxiv.org/abs/1909.00066" target="_blank">counterfactual evaluation in child welfare</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2018</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.nsfgrfp.org/resources/about-grfp/">NSF GRFP Fellow</a>.</td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Teaching</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr width="90%" valign="center" align="left">
    <td style="padding-left: 3%;">
      Amanda particularly enjoys teaching and mentorship opportunties. She served as a teaching assistant for Matt Gormley and Tom Mitchell's <a href="http://mlcourse.org">Introduction to Machine Learning</a> in 2021. She served as a project lead of the <a href="http://ai-4-all.org/">AI4ALL</a> summer program at CMU, where she introduced high school students to algorithmic fairness in the criminal justice system using the COMPAS dataset (see Github <a href= "https://github.com/mandycoston/compas-analysis">project</a>). She also participates in the AI undergradate mentoring program and at CMU. As an undergraduate, she was a teaching assistant for Brian Kernighan's <a href="https://www.cs.princeton.edu/courses/archive/fall14/cos109/01intro.pdf">Computers in our World</a> course at Princeton.
    </td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Service</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5"> 
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Steering Committee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://ml4d.notion.site/Machine-Learning-for-the-Developing-World-ML4D-2021-548251eab3df4517819c4742c2e5c853">ML4D workshop</a> 2022, 2021, 2020, 2019.</td>
    <tr>
      <td width=30%" valign="top" align="right"><b><i>Referee</b></td>
      <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.nature.com/nathumbehav/">Nature Human Behaviour</a>.</td>
    </tr>

  <tr>
    <td width=30%" valign="top" align="right"><b><i>Referee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.tandfonline.com/journals/uasa20">JASA</a>.</td>
  </tr>
<tr>
 <td width="30%" valign="top" align="right"><b><i>Referee</b></td>
 <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://rss.onlinelibrary.wiley.com/journal/14679868">Journal of Royal Statistical Society Series B</a>.</td>
</tr>
<tr>
  <td width="30%" valign="top" align="right"><b><i>Referee</b></td>
  <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.springer.com/journal/10618">Data Mining and Knowledge Discovery</a>.</td>
</tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Reviewer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://iclr.cc/Conferences/2022/">ICLR</a> 2023, 2022.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Ethical reviewer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://nips.cc/Conferences/2022">NeurIPS</a> 2022, 2021.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Reviewer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://nips.cc/Conferences/2022">NeurIPS</a> 2022, 2021, 2020.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Reviewer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://neurips.cc/Conferences/2022/CallForDatasetsBenchmarks">NeurIPS Datasets and Benchmarks</a> 2022, 2021.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Program Committee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://eaamo.org">EAAMO</a> 2022.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Program Committee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://facctconference.org/">FAccT</a> 2022, 2021, 2020.</td>
  </tr>
  
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Reviewer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://icml.cc/Conferences/">ICML</a> 2022, 2021, 2020.</td>
  </tr>
  <!-- <tr>
    <td width="12%" valign="top" align="right"><b><i>2021</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://facctconference.org/2021/">FAccT 2021</a>.</td>
  </tr> -->
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Area Chair</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://iclr.cc/virtual/2021/workshop/2132">ICLR Workshop on Responsible AI</a> 2021.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Program Commitee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://www.aies-conference.com/2020/index.html">AIES</a> 2020.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Program Committee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://aaai.org/Conferences/AAAI-20/aaai20specialtrackcall/">AAAI Emerging Track on AI for Social Impact</a> 2020.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Program Committee</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://aiforgood2019.github.io/">IJCAI Workshop on AI for Social Good</a> 2019.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Co-organizer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;">Fairness, Ethics, Accountability, and Transparency (FEAT) reading group at CMU 2019-2020.</td>
  </tr>
  <tr>
    <td width="30%" valign="top" align="right"><b><i>Co-organizer</b></td>
    <td width="70%" valign="top" align="left" style="padding-left: 10px;"><a href="https://ml4d.notion.site/Machine-Learning-for-the-Developing-World-ML4D-2021-548251eab3df4517819c4742c2e5c853">ML4D workshop</a> at NeurIPS 2018 and NeurIPS 2019. ML4D showcases ML research by and for the developing world.</td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Background</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr width="90%" valign="center" align="left">
    <td style="padding-left: 3%;">
      Amanda graduated from <a href="https://www.princeton.edu/">Princeton University</a> in 2013 with a degree in computer science and a certificate in the <a href="https://spia.princeton.edu/">Princeton School of Public Policy and International Affairs</a>. For her undergraduate thesis, she analyzed how machine learning techniques can improve the diagnosis of pediatric tuberculosis in collaboration with Jocelyn Tang ('14) and under the guidance of <a href="http://rob.schapire.net/">Robert Schapire</a>. In 2019 she earned her <a href="https://www.ml.cmu.edu/academics/secondary-ms.html">Master of Science in Machine Learning</a> from CMU.

    </td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellpadding="10">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;Contact</sectionheading>
    <p style="margin-left: 10px;">
      Hamburg Hall<br>
      Room 211<br>
      Heinz School of Information Systems and Public Policy<br>
      Carnegie Mellon University<br>
      Pittsburgh, PA 15213
    </p>
  </td></tr>
</table><hr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><p align="right"><font size="1.5">
    Template modified from <a href="https://siddancha.github.io" target="_blank">here</a>
    </font></p></td></tr>
</table>

  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>

</html>
