<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }

  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600; /* 1000 */
  }
  strong {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 29px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Nunito', Verdana, Helvetica, sans-serif;
    font-size: 50px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }

  img.pub {
    padding: 0px;
    margin: 0px;
    border-radius:15px;
    border:1px solid black;
  }

  .paper {
    font-size: 12px;
    margin-left: 30px;
  }

  pre {
    border: solid;
    border-width: 1px;
    padding: 5px;
  }

  sticker {
    color:white;
    background-color: red;
    font-size: 13px;
    font-weight: bold;
    vertical-align: center;
    padding-left: 2px;
    padding-right: 2px;
  }

  </style>
  <link rel="shortcut icon" href="https://www.cs.cmu.edu/sites/default/files/favicon_0.ico" type="image/vnd.microsoft.icon">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Amanda Coston</title>
  <meta name="Amanda Coston's Homepage" http-equiv="Content-Type" content="Amanda Coston's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Nunito:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Amanda Coston</font><br> -->
    <pageheading>Amanda Coston</pageheading><br>
    <b>email</b>:&nbsp
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <script>
    emailScramble = new scrambledString(document.getElementById('email'),
        'emailScramble', 'doc@cuoctes.mu.san',
        [17,3,9,8,12,14,6,2,5,16,4,11,13,18,15,10,1,7]);
    </script>
  </p>

  <tr>
    <td width="40%" valign="top"><a href="images/mandy.jpeg"><img src="images/mandy.jpeg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    <a href="CV.pdf">CV</a> |
    <!-- <a href="bio.text" target="_blank">Bio</a> | -->
    <a href="https://scholar.google.com/citations?user=8U7d-_MAAAAJ&hl=en">Google Scholar</a> |
    <a href="https://github.com/mandycoston">Github</a> |
    <a href="https://twitter.com/amandacoston">Twitter</a>
    </p>
    </td>
    <td width="60%" valign="top" align="justify">
      <p>
        Amanda Coston is a PhD student in <a href="https://www.ml.cmu.edu/current-students/joint-phd-in-machine-learning-and-public-policy-requirements.html">Machine Learning and Public Policy</a> at <a href="https://www.cmu.edu">Carnegie Mellon University</a> (CMU). Her <a href="research.html">research</a> considers the impact of algorithmic risk assessments in settings such as child welfare screening, criminal justice, and loan approvals. She is particularly interested in how techniques from causal inference and transfer learning can resolve current limitations of these systems.  She is advised by <a href= "https://www.andrew.cmu.edu/user/achoulde/">Alexandra Chouldechova</a> and <a href="http://www.ehkennedy.com/">Edward H. Kennedy.</a>
      </p>
      <p>
        Amanda is an <a href="https://www.nsfgrfp.org/resources/about-grfp/">NSF GRFP Fellow</a> and a <a href="https://www.cmu.edu/news/stories/archives/2020/august/gates-presidential-fellows.html">K & L Gates Presidential Fellow</a> in Ethics and Computational Technologies. In 2019 she was a recipient of the Tata Consultancy Services (TCS) Presidential Fellowship Her research on counterfactual risk assessments and evalution for child welfare screening won the 2018 <a href="https://www.cmu.edu/cmnews/extra/060113_konda.html">Suresh Konda Best First Student Research Paper Award</a> from the <a href="https://www.heinz.cmu.edu/">Heinz College</a>.
      </p>

      <p>
        Amanda graduated from <a href="https://www.princeton.edu/">Princeton University</a> in 2013 with a degree in computer science and a certificate in the <a href="https://spia.princeton.edu/">Princeton School of Public Policy and International Affairs</a>. For her undergraduate thesis, she analyzed how machine learning techniques can improve the diagnosis of pediatric tuberculosis in collaboration with Jocelyn Tang ('14) and under the guidance of <a href="http://rob.schapire.net/">Robert Schapire</a>. In 2019 she earned her <a href="https://www.ml.cmu.edu/academics/secondary-ms.html">Master of Science in Machine Learning</a> from CMU.
      </p>
    </td>
  </tr>
</table><hr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;News</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr>
    <td width="20%" valign="top" align="right"><b><i>June 07, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;">Starting internship at <a href="https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/">Facebook Responsible AI</a>.</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>May 18, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;">Featured on <a href="https://www.placekey.io/blog/amanda-coston-carnegie-mellon">Placekey Spotlight</a>.</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>May 08, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;">Our <a href="https://arxiv.org/abs/2101.00352">research paper</a> on characterizing fairness over the set of good models under selective stickers accepted at <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>May 04, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;"><sticker>TALK</sticker> Invited talk at <a href="https://jhsphcausalinference.weebly.com/">Johns Hopkins Causal Inference Working Group</a> on counterfactual predictions for decision-making. Check out the <a href="https://www.youtube.com/watch?v=Ubt_sH2qRMg">video here</a>!</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>April 22, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;"><sticker>TALK</sticker> Invited talk at <a href="https://www.placekey.io/">PlaceKey</a> COVID-19 Research Consortium on auditing mobility data for disparate coverage by race and age. Check out the <a href="https://www.placekey.io/seminars/mobility-data-used-to-respond-to-covid19-could-be-biased">video here</a>!</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>April 16, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;">CMU <a href ="https://blog.ml.cmu.edu/2021/04/16/counterfactual-predictions-under-runtime-confounding/"> ML Blog Post </a> on counterfactual predictions under runtime confounding.</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>April 05, 2021</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;"><i>The Wall Street Journal</i> featured our research on auditing mobility data for demographic bias! The piece is titled <a href ="https://www.wsj.com/articles/smartphone-location-data-can-leave-out-those-most-hit-by-covid-19-11617627615"><i>Smartphone Location Data Can Leave Out Those Most Hit by Covid-19</i></a>.</td>
  </tr>
  <tr>
    <td width="20%" valign="top" align="right"><b><i>Nov. 18, 2020</i></b></td>
    <td width="80%" valign="top" align="left" style="padding-left: 10px;"><i>VentureBeat</i> featured our research on auditing mobility data for demographic bias! The piece is titled <a href ="https://venturebeat.com/2020/11/18/stanford-and-carnegie-mellon-find-race-and-age-bias-in-mobility-data-that-drives-covid-19-policy/"> <i>Stanford and Carnegie Mellon find race and age bias in mobility data that drives COVID-19 policy</i></a>.</td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

  <tr>
    <td width="40%" valign="top" align="center"><a href="projects/active-safety-envelopes-with-guarantees" target="_blank"><img class="pub" src="projects/active-safety-envelopes-with-guarantees/resources/thumbnail/thumbnail_400px.gif" alt="image not found" width="93%""></a></td>
    <td width="60%" valign="top">
      <p><a href="projects/active-safety-envelopes-with-guarantees" target="_blank">
      <sticker>NEW!</sticker> 
      <heading>Active Safety Envelopes using Light Curtains with Probabilistic Guarantees</heading></a><br>
      <b>Amanda Coston</b>, Gaurav Pathak, David Held, Srinivasa Narasimhan<br>
      RSS 2021
      </p>

      <div>
      <a href="projects/active-safety-envelopes-with-guarantees" target="_blank">webpage</a> |
      <a href="javascript:toggleblock('rss21_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2107.04000.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('rss21')" class="togglebib">bibtex</a> |
      <a href="https://youtu.be/1PUAjzcTz5g" target="_blank">talk</a>


      <p align="justify"> <i id="rss21_abs">To safely navigate unknown environments, robots must accurately perceive dynamic obstacles. Instead of directly measuring the scene depth with a LiDAR sensor, we explore the use of a much cheaper and higher resolution sensor: <a href="https://www.cs.cmu.edu/~ILIM/light_curtains" target="_blank">programmable light curtains</a>. Light curtains are controllable depth sensors that sense only along a surface that a user selects. We use light curtains to estimate the safety envelope of a scene: a hypothetical surface that separates the robot from all obstacles. We show that generating light curtains that sense <b>random</b> locations (from a particular distribution) can quickly discover the safety envelope for scenes with unknown objects. Importantly, we produce theoretical safety guarantees on the probability of detecting an obstacle using random curtains. We combine random curtains with a machine learning based model that forecasts and tracks the motion of the safety envelope efficiently. Our method accurately estimates safety envelopes while providing probabilistic safety guarantees that can be used to certify the efficacy of a robot perception system to detect and avoid dynamic obstacles. We evaluate our approach in a simulated urban driving environment and a real-world environment with moving pedestrians using a light curtain device and show that we can estimate safety envelopes efficiently and effectively.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('rss21_abs');
      </script>
      </div>
    </td>
  </tr>

<tr>
  <td colspan="2" style="padding: 0px">
    <div class="paper" id="rss21">
      <pre xml:space="preserve">
@inproceedings{Ancha-RSS-21, 
  author    = {Amanda Coston AND Gaurav Pathak AND Srinivasa Narasimhan AND David Held}, 
  title     = {Active Safety Envelopes using Light Curtains with Probabilistic Guarantees}, 
  booktitle = {Proceedings of Robotics: Science and Systems}, 
  year      = {2021}, 
  address   = {Virtual}, 
  month     = {July}, 
  doi       = {10.15607/rss.2021.xvii.045} 
}</pre>
    </div>
  </td>
</tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://soulslicer.github.io/rgb-lc-fusion" target="_blank"><img class="pub" src="images/cvpr21.png" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://soulslicer.github.io/rgb-lc-fusion" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Exploiting & Refining Depth Distributions with Triangulation Light Curtains</heading></a><br>
      Yaadhav Raaj, <b>Amanda Coston</b>, Robert Tamburo, David Held,<br>Srinivasa Narasimhan<br>
      CVPR 2021
      </p>

      <div>
      <a href="https://soulslicer.github.io/rgb-lc-fusion" target="_blank">webpage</a> |
      <a href="javascript:toggleblock('cvpr21_abs')">abstract</a> |
      <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Raaj_Exploiting__Refining_Depth_Distributions_With_Triangulation_Light_Curtains_CVPR_2021_paper.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('cvpr21')" class="togglebib">bibtex</a> |
      <a href="https://youtu.be/kIjn3U8luV0" target="_blank">talk</a>


      <p align="justify"> <i id="cvpr21_abs">Active sensing through the use of adaptive depth sensors is a nascent field, with potential in areas such as advanced driver-assistance systems (ADAS). They do however require dynamically driving a laser / light-source to a specific location to capture information, with one such class of sensors being <a href="https://www.cs.cmu.edu/~ILIM/light_curtains" target="_blank">programmable light curtains</a>. In this work, we introduce a novel approach that exploits prior depth distributions from RGB cameras to drive a light curtain's laser line to regions of uncertainty to get new measurements. These measurements are utilized such that depth uncertainty is reduced and errors get corrected recursively. We show real-world experiments that validate our approach in outdoor and driving settings, and demonstrate qualitative and quantitative improvements in depth RMSE when RGB cameras are used in tandem with a light curtain.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('cvpr21_abs');
      </script>
      </div>
    </td>
  </tr>

<tr>
  <td colspan="2" style="padding: 0px">
    <div class="paper" id="cvpr21">
      <pre xml:space="preserve">
@inproceedings{cvpr2021raajexploiting,
  author    = {Yaadhav Raaj, Amanda Coston, Robert Tamburo, David Held, Srinivasa Narasimhan},
  title     = {Exploiting and Refining Depth Distributions with Triangulation Light Curtains},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021}
}</pre>
    </div>
  </td>
</tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="projects/active-perception-light-curtains" target="_blank"><img class="pub" src="projects/active-perception-light-curtains/resources/thumbnail.gif" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="projects/active-perception-light-curtains" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Active Perception using Light Curtains for Autonomous Driving</heading></a><br>
      <b>Amanda Coston</b>, Yaadhav Raaj, Peiyun Hu, Srinivasa Narasimhan,<br>  David Held<br>
      ECCV 2020 <span style="color:red">(Spotlight presentation)</span>
      </p>

      <div>
      <a href="projects/active-perception-light-curtains" target="_blank">webpage</a> |
      <a href="javascript:toggleblock('eccv20_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2008.02191.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('eccv20')" class="togglebib">bibtex</a> |
      <a href="https://youtu.be/WSb5T3HFE7w" target="_blank">short talk</a> |
      <a href="https://youtu.be/uRP63hHArU0" target="_blank">long talk</a> |
      <a href="projects/active-perception-light-curtains/resources/long_talk.pdf" target="_blank">slides</a> |
      <a href="https://github.com/siddancha/active-perception-light-curtains" target="_blank">code</a>


      <p align="justify"> <i id="eccv20_abs">Most real-world 3D sensors such as LiDARs perform fixed scans of the entire environment, while being decoupled from the recognition system that processes the sensor data. In this work, we propose a method for 3D object recognition using light curtains, a resource-efficient controllable sensor that measures depth at user-specified locations in the environment. Crucially, we propose using prediction uncertainty of a deep learning based 3D point cloud detector to guide active perception. Given a neural network's uncertainty, we derive an optimization objective to place light curtains using the principle of maximizing information gain. Then, we develop a novel and efficient optimization algorithm to maximize this objective by encoding the physical constraints of the device into a constraint graph and optimizing with dynamic programming. We show how a 3D detector can be trained to detect objects in a scene by sequentially placing uncertainty-guided light curtains to successively improve detection accuracy.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('eccv20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="eccv20">
        <pre xml:space="preserve">
@inproceedings{ancha2020eccv,
  author    = {Ancha, Siddharth AND Raaj, Yaadhav AND Hu, Peiyun AND Narasimhan, Srinivasa G.
              AND Held, David},
  editor    = {Vedaldi, Andrea AND Bischof, Horst AND Brox, Thomas AND Frahm, Jan-Michael},
  title     = {Active Perception Using Light Curtains for Autonomous Driving},
  booktitle = {Computer Vision -- ECCV 2020},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {751--766},
  isbn      = {978-3-030-58558-7}
}</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://www.jianrenw.com/Self-Supervised-3D-Data-Association" target="_blank"><img class="pub" src="images/iros20.jpeg" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://www.jianrenw.com/Self-Supervised-3D-Data-Association" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Uncertainty-Aware Self-Supervised 3D Data Association</heading></a><br>
      Jianren Wang, <b>Amanda Coston</b>, Yi-Ting Chen, David Held<br>
      IROS 2020
      </p>

      <div>
      <a href="https://www.jianrenw.com/Self-Supervised-3D-Data-Association" target="_blank">webpage</a> |
      <a href="javascript:toggleblock('iros20_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2008.08173v1.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('iros20')" class="togglebib">bibtex</a> |
      <a href="https://youtu.be/UkbiusxvAyk" target="_blank">talk</a> |
      <a href="http://www.jianrenw.com/Self-Supervised-3D-Data-Association/resources/slides.pptx" target="_blank">slides</a> |
      <a href="https://github.com/jianrenw/Self-Supervised-3D-Data-Association" target="_blank">code</a>


      <p align="justify"> <i id="iros20_abs">3D object trackers usually require training on large amounts of annotated data that is expensive and time-consuming to collect. Instead, we propose leveraging vast unstickered datasets by self-supervised metric learning of 3D object trackers, with a focus on data association. Large scale annotations for unstickered data are cheaply obtained by automatic object detection and association across frames. We show how these self-supervised annotations can be used in a principled manner to learn point-cloud embeddings that are effective for 3D tracking. We estimate and incorporate uncertainty in self-supervised tracking to learn more robust embeddings, without needing any stickered data. We design embeddings to differentiate objects across frames, and learn them using uncertainty-aware self-supervised training. Finally, we demonstrate their ability to perform accurate data association across frames, towards effective and accurate 3D tracking.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('iros20_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="iros20">
        <pre xml:space="preserve">
@inproceedings{jianren20s3da,
  author    = {Wang, Jianren AND Ancha, Siddharth AND Chen, Yi-Ting AND Held, David},
  title     = {Uncertainty-aware Self-supervised 3D Data Association},
  booktitle = {IROS},
  year      = {2020}
}</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://jnan1.github.io/FlowVerify" target="_blank"><img class="pub" src="images/corl19.png" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://jnan1.github.io/FlowVerify/" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Combining Deep Learning and Verification for Precise Object Instance Detection</heading></a><br>
      <b>Amanda Coston</b>*, Junyu Nan*, David Held<br>
      CoRL 2019
      </p>

      <div>
      <a href="https://jnan1.github.io/FlowVerify" target="_blank">webpage</a> |
      <a href="javascript:toggleblock('corl19_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/1912.12270.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('corl19')" class="togglebib">bibtex</a> |
      <a href="https://www.youtube.com/watch?time_continue=12696&v=QaCuEv_7lfs" target="_blank">talk</a> |
      <a href="https://github.com/siddancha/FlowVerify" target="_blank">code</a>


      <p align="justify"> <i id="corl19_abs">Deep learning object detectors often return false positives with very high confidence. Although they optimize generic detection performance, such as mean average precision (mAP), they are not designed for reliability. For a reliable detection system, if a high confidence detection is made, we would want high certainty that the object has indeed been detected. To achieve this, we have developed a set of verification tests which a proposed detection must pass to be accepted. We develop a theoretical framework which proves that, under certain assumptions, our verification tests will not accept any false positives. Based on an approximation to this framework, we present a practical detection system that can verify, with high precision, whether each detection of a machine-learning based object detector is correct. We show that these tests can improve the overall accuracy of a base detector and that accepted examples are highly likely to be correct. This allows the detector to operate in a high precision regime and can thus be used for robotic perception systems as a reliable instance detection method.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('corl19_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="corl19">
        <pre xml:space="preserve">
@inproceedings{FlowVerify2019CoRL,
  author    = {Amanda Coston AND Junyu Nan AND David Held},
  editor    = {Leslie Pack Kaelbling AND Danica Kragic AND Komei Sugiura},
  title     = {Combining Deep Learning AND Verification for Precise Object Instance Detection},
  booktitle = {3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan,
               October 30 - November 1, 2019, Proceedings},
  series    = {Proceedings of Machine Learning Research},
  volume    = {100},
  pages     = {122--141},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v100/ancha20a.html},
  timestamp = {Mon, 25 May 2020 15:01:26 +0200},
  biburl    = {https://dblp.org/rec/conf/corl/AnchaNH19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}</pre>
      </div>
    </td>
  </tr>

  <tr><td><sectionheading style="font-size: 19px;">&nbsp;&nbsp;Older Work</sectionheading></td></tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/pdf/1805.08403.pdf" target="_blank"><img class="pub" src="images/miccai18.png" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/pdf/1805.08403.pdf" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Autofocus Layer for Semantic Segmentation</heading></a><br>
      Yao Qin, Konstantinos Kamnitsas, <b>Amanda Coston</b>, Jay Nanavati, Garrison Cottrell, Antonio Criminisi, Aditya Nori<br>
      MICCAI 2018 <span style="color:red">(Oral presentation)</span>
      </p>

      <div>
      <a href="javascript:toggleblock('miccai18_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/1805.08403.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('miccai18')" class="togglebib">bibtex</a> |
      <a href="https://github.com/yaq007/Autofocus-Layer" target="_blank">code</a>

      <p align="justify"> <i id="miccai18_abs">We propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the effective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising multiple convolutional layers with different dilation rates, combined with an attention mechanism that learns to focus on the optimal scales driven by context. By sharing the weights of parallel convolutions, we make the network scale-invariant, with only a modest increase in the number of parameters. The proposed autofocus layer can be easily integrated into existing networks to improve the model's representational power. Our method achieves very promising performance on the challenging tasks of multi-organ segmentation in pelvic CT scans and brain tumor segmentation in MRI scans.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('miccai18_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="miccai18">
        <pre xml:space="preserve">
@inproceedings{qin2018autofocus,
  title        = {Autofocus layer for semantic segmentation},
  author       = {Qin, Yao AND Kamnitsas, Konstantinos AND Ancha, Siddharth AND Nanavati, Jay
                  AND Cottrell, Garrison AND Criminisi, Antonio AND Nori, Aditya},
  booktitle    = {International conference on medical image computing and computer-assisted
                  intervention (MICCAI)},
  pages        = {603--611},
  year         = {2018},
  organization = {Springer}
}</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://www.springerprofessional.de/en/lifted-auto-context-forests-for-brain-tumour-segmentation/12216560" target="_blank"><img class="pub" src="images/miccai16.png" alt="image not found" width="93%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://www.springerprofessional.de/en/lifted-auto-context-forests-for-brain-tumour-segmentation/12216560" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Lifted Auto-Context Forests for Brain Tumour Segmentation</heading></a><br>
      Lo&#xEF;c Le Folgoc, Aditya V. Nori, <b>Amanda Coston</b>, Antonio Criminisi<br>
      MICCAI 2016 BraTS Challenge <span style="color:red">(Winner)</span>
      </p>

      <div>
      <a href="javascript:toggleblock('miccai16_abs')">abstract</a> |
      <a href="https://www.springerprofessional.de/en/lifted-auto-context-forests-for-brain-tumour-segmentation/12216560" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('miccai16')" class="togglebib">bibtex</a> |

      <p align="justify"> <i id="miccai16_abs">We revisit <i>Auto-Context Forests</i> for brain tumour segmentation in multi-channel magnetic resonance images, where semantic context is progressively built and refined via successive layers of Decision Forests (DFs). Specifically, we make the following contributions: (1) improved generalization via an efficient node-splitting criterion based on hold-out estimates, (2) increased compactness at the tree level, thereby yielding shallow discriminative ensembles trained orders of magnitude faster, and (3) guided semantic bagging that exposes latent data-space semantics captured by forest pathways. The proposed framework is practical: the per-layer training is fast, modular and robust. It was a top performer in the MICCAI 2016 BraTS (Brain Tumour Segmentation) challenge, and this paper aims to discuss and provide details about the challenge entry.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('miccai16_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="miccai16">
        <pre xml:space="preserve">
@inproceedings{le2016lifted,
  title       = {Lifted auto-context forests for brain tumour segmentation},
  author      = {Le Folgoc, Loic AND Nori, Aditya V AND Ancha, Siddharth AND Criminisi, Antonio},
  booktitle   = {International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and
                 Traumatic Brain Injuries},
  pages       = {171--183},
  year        = {2016},
  organization= {Springer}
}</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/pdf/1606.02275.pdf" target="_blank"><img src="images/neurips16.png" alt="image not found" width="72%"></a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/pdf/1606.02275.pdf" target="_blank">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Measuring the reliability of MCMC inference with bidirectional Monte Carlo</heading></a><br>
      Roger B. Grosse, <b>Amanda Coston</b>, Daniel M. Roy<br>
      NeurIPS 2016</span>
      </p>

      <div>
      <a href="javascript:toggleblock('neurips16_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/1606.02275.pdf" target="_blank">pdf</a> |
      <a shape="rect" href="javascript:togglebib('neurips16')" class="togglebib">bibtex</a> |
      <a href="https://github.com/siddancha/AutoBDMC" target="_blank">code</a>

      <p align="justify"> <i id="neurips16_abs">Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We present <i>Bounding Divergences with REverse Annealing (BREAD)</i>, a protocol for validating the relevance of simulated data experiments to real datasets, and integrate it into two probabilistic programming languages: <a href="http://webppl.org/" target="_blank">WebPPL</a> and <a href="https://mc-stan.org/" target="_blank">Stan</a>. As an example of how BREAD can be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in both WebPPL and Stan.</i></p>
      <script xml:space="preserve" language="JavaScript">
        hideblock('neurips16_abs');
      </script>
      </div>
    </td>
  </tr>

  <tr>
    <td colspan="2" style="padding: 0px">
      <div class="paper" id="neurips16">
        <pre xml:space="preserve">
@inproceedings{NIPS2016_0e9fa1f3,
  author    = {Grosse, Roger B AND Ancha, Siddharth AND Roy, Daniel M},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {D. Lee AND M. Sugiyama AND U. Luxburg AND I. Guyon AND R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Measuring the reliability of MCMC inference with bidirectional Monte Carlo},
  url       = {https://proceedings.neurips.cc/paper/2016/file/
               0e9fa1f3e9e66792401a6972d477dcc3-Paper.pdf},
  volume    = {29},
  year      = {2016}
}</pre>
      </div>
    </td>
  </tr>

</table><hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Awards</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Awarded the <a href="https://www.cmu.edu/news/stories/archives/2020/august/gates-presidential-fellows.html">K & L Gates Presidential Fellowship</a> in Ethics and Computational Technologies.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2019</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Awarded the Tata Consultancy Services (TCS) Presidential Fellowship.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2018</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Awarded the 2018 <a href="https://www.cmu.edu/cmnews/extra/060113_konda.html">Suresh Konda Best First Student Research Paper Award</a> from the <a href="https://www.heinz.cmu.edu/">Heinz College</a> for counterfactual risk assessments and evalution for child welfare screening.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2018</i></b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Awarded the <a href="https://www.nsfgrfp.org/resources/about-grfp/">NSF GRFP Fellowship</a>.</td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Teaching</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr width="90%" valign="center" align="left">
    <td style="padding-left: 3%;">
      Amanda particularly enjoys teaching and mentorship opportunties. She served as a teaching assistant for Matt Gormley and Tom Mitchell's <a href="http://mlcourse.org">Introduction to Machine Learning</a> in 2021. She served as a project lead of the <a href="http://ai-4-all.org/">AI4ALL</a> summer program at CMU, where she introduced high school students to algorithmic fairness in the criminal justice system using the COMPAS dataset (see Github <a href= "https://github.com/mandycoston/compas-analysis">project</a>). She also participated in the AI undergradate mentoring program at CMU.
    </td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Service</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2021</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://facctconference.org/2021/">FAccT 2021</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2021</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Area chair for the <a href="https://iclr.cc/virtual/2021/workshop/2132">ICLR 2021 Workshop on Responsible AI</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2021</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Reviewer for <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2021</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Reviewer for <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://facctconference.org/2020/">FAT* 2020</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://www.aies-conference.com/2020/index.html">AIES 2020</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://aaai.org/Conferences/AAAI-20/aaai20specialtrackcall/">AAAI 2020 Emerging Track on AI for Social Impact</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Reviewer for <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2020</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Reviewer for <a href="https://icml.cc/Conferences/2020">ICML 2020</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2019</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Programme committee member for <a href="https://aiforgood2019.github.io/">IJCAI 2019 Workshop on AI for Social Good</a>.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2019</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Co-organizer if the Fairness, Ethics, Accountability, and Transparency (FEAT) reading group at CMU.</td>
  </tr>
  <tr>
    <td width="12%" valign="top" align="right"><b><i>2018, 19</b></td>
    <td width="88%" valign="top" align="left" style="padding-left: 10px;">Co-organizer of the <a href="https://ml4d.notion.site/Machine-Learning-for-the-Developing-World-ML4D-2021-548251eab3df4517819c4742c2e5c853">ML4D workshop</a> at NeurIPS 2018 and NeurIPS 2019, which brings machine learning researchers together with field practitioners to discuss ML in the context of the developing world. The workshop explored the risks and challenges of using ML4D.</td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Background</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
  <tr width="90%" valign="center" align="left">
    <td style="padding-left: 3%;">
      Amanda graduated from <a href="https://www.princeton.edu/">Princeton University</a> in 2013 with a degree in computer science and a certificate in the <a href="https://spia.princeton.edu/">Princeton School of Public Policy and International Affairs</a>. For her undergraduate thesis, she analyzed how machine learning techniques can improve the diagnosis of pediatric tuberculosis in collaboration with Jocelyn Tang ('14) and under the guidance of <a href="http://rob.schapire.net/">Robert Schapire</a>. In 2019 she earned her <a href="https://www.ml.cmu.edu/academics/secondary-ms.html">Master of Science in Machine Learning</a> from CMU.

    </td>
  </tr>
</table>
<hr style="margin-top: 20px;">

<table width="100%" align="center" border="0" cellpadding="10">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;Contact</sectionheading>
    <p style="margin-left: 10px;">
      Gates Hillman Center<br>
      Room 8021<br>
      Machine Learning Depatment<br>
      Carnegie Mellon University<br>
      Pittsburgh, PA 15213
    </p>
  </td></tr>
</table><hr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><p align="right"><font size="1.5">
    Template modified from <a href="https://siddancha.github.io" target="_blank">here</a>
    </font></p></td></tr>
</table>

  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>

</html>
